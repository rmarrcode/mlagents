{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "separate_critic: False\n",
      "Found 6 checkpoint files.\n",
      "[1/6] Loading Seeker-499496.pt …\n",
      "[2/6] Loading Seeker-999446.pt …\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from trainers.torch.networks import SplitValueSharedActorCritic\n",
    "from mlagents_envs.base_env import ObservationSpec, DimensionProperty, ObservationType, ActionSpec, BehaviorSpec\n",
    "from mlagents.trainers.settings import NetworkSettings, TrainerSettings\n",
    "from trainers.policy.torch_policy import TorchPolicy\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "def natural_sort_key(path):\n",
    "    # extract all integers and sort by them\n",
    "    nums = re.findall(r'\\d+', os.path.basename(path))\n",
    "    return [int(n) for n in nums] if nums else [float('inf')]\n",
    "\n",
    "def build_policy(seed: int,\n",
    "                 behavior_spec: BehaviorSpec,\n",
    "                 trainer_settings: TrainerSettings,\n",
    "                 network_settings: NetworkSettings,\n",
    "                 tanh_squash: bool,\n",
    "                 separate_critic: bool,\n",
    "                 condition_sigma_on_obs: bool,\n",
    "                 load_critic_only: str):\n",
    "    \"\"\"\n",
    "    Instantiate a TorchPolicy just as you did interactively.\n",
    "    \"\"\"\n",
    "    policy = TorchPolicy(\n",
    "        seed=seed,\n",
    "        behavior_spec=behavior_spec,\n",
    "        trainer_settings=trainer_settings,\n",
    "        tanh_squash=tanh_squash,\n",
    "        separate_critic=separate_critic,\n",
    "        condition_sigma_on_obs=condition_sigma_on_obs,\n",
    "        load_critic_only=load_critic_only\n",
    "    )\n",
    "    return policy\n",
    "\n",
    "def make_grid_positions(xmin, xmax, ymin, ymax, step=1):\n",
    "    \"\"\"\n",
    "    Returns a list containing a single tensor of shape [N, obs_dim],\n",
    "    where N = ((xmax-xmin)/step+1)*((ymax-ymin)/step+1).\n",
    "    \"\"\"\n",
    "    positions = []\n",
    "    for y in range(ymin, ymax + 1, step):\n",
    "        for x in range(xmin, xmax + 1, step):\n",
    "            # [x-0.5, 0.5, y-0.5] + zeros(9)\n",
    "            pos = [x - 0.5, 0.5, y - 0.5] + [0.0] * 9\n",
    "            positions.append(pos)\n",
    "    tensor = torch.tensor(positions, dtype=torch.float32)\n",
    "    return [tensor]\n",
    "\n",
    "def plot_field(field,\n",
    "               out_path,\n",
    "               capture_path,\n",
    "               cmap='viridis',\n",
    "               alpha=0.4,\n",
    "               vmin=None,\n",
    "               vmax=None,\n",
    "               dpi=150):\n",
    "    \"\"\"\n",
    "    field         : 2D numpy array of your grid values\n",
    "    out_path      : where to save the overlayed png\n",
    "    capture_path  : path to your background Capture.PNG\n",
    "    cmap          : matplotlib colormap\n",
    "    alpha         : heatmap transparency (0..1)\n",
    "    vmin,vmax     : manual color‐scale limits (optional)\n",
    "    dpi           : resolution for saved PNG\n",
    "    \"\"\"\n",
    "    # 1) load background\n",
    "    bg = mpimg.imread(capture_path)        # shape = (H, W, 3)\n",
    "    rows, cols = field.shape\n",
    "\n",
    "    # 2) prep figure so data‐coords = grid coords\n",
    "    fig, ax = plt.subplots(figsize=(cols/2, rows/2))\n",
    "    extent = [cols, 0, rows, 0]  # Flip y-axis by swapping bottom and top\n",
    "\n",
    "    # 3) draw background (zorder=0)\n",
    "    ax.imshow(bg,\n",
    "              extent=extent,\n",
    "              aspect='auto',\n",
    "              zorder=0)\n",
    "\n",
    "    # 4) overlay translucent heatmap (zorder=1)\n",
    "    flipped_field = np.flipud(field)  # Flip the field on the y-axis\n",
    "    im = ax.imshow(flipped_field,\n",
    "                   cmap=cmap,\n",
    "                   alpha=alpha,\n",
    "                   extent=extent,\n",
    "                   interpolation='nearest',\n",
    "                   aspect='auto',\n",
    "                   vmin=vmin if vmin is not None else np.nanmin(field),\n",
    "                   vmax=vmax if vmax is not None else np.nanmax(field),\n",
    "                   zorder=1)\n",
    "\n",
    "    # 5) strip axes/margins\n",
    "    ax.axis('off')\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "\n",
    "    # 6) save\n",
    "    fig.savefig(out_path,\n",
    "                dpi=dpi,\n",
    "                bbox_inches='tight',\n",
    "                pad_inches=0)\n",
    "    plt.close(fig)\n",
    "\n",
    "def make_gif_from_images(image_paths, out_gif, fps=2):\n",
    "    imgs = []\n",
    "    for im_path in image_paths:\n",
    "        imgs.append(imageio.imread(im_path))\n",
    "    imageio.mimsave(out_gif, imgs, fps=fps)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # === CONFIGURATION ===\n",
    "    run_name = \"4-22-ppo-0\"\n",
    "    seeker_dir = f\"/home/rmarr/Projects/visibility-game-env/results/{run_name}/Seeker\"\n",
    "    out_dir    = os.path.join(seeker_dir, \"heatmap_frames\")\n",
    "    gif_path   = os.path.join(seeker_dir, f\"{run_name}_seeker_evolution.gif\")\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # === RECREATE YOUR SPECS & POLICY ===\n",
    "    seed = 5404\n",
    "    observation_specs = [ObservationSpec(\n",
    "        name=\"position_observation\",\n",
    "        shape=(12,),\n",
    "        dimension_property=(DimensionProperty.NONE,),\n",
    "        observation_type=ObservationType.DEFAULT\n",
    "    )]\n",
    "    action_spec = ActionSpec(continuous_size=0, discrete_branches=(5,))\n",
    "    behavior_spec = BehaviorSpec(\n",
    "        observation_specs=observation_specs,\n",
    "        action_spec=action_spec\n",
    "    )\n",
    "    trainer_settings = TrainerSettings(dual_critic=True)\n",
    "    network_settings = NetworkSettings(\n",
    "        deterministic=False,\n",
    "        memory=None,\n",
    "        hidden_units=128,\n",
    "        num_layers=2,\n",
    "    )\n",
    "\n",
    "    policy = build_policy(\n",
    "        seed=seed,\n",
    "        behavior_spec=behavior_spec,\n",
    "        trainer_settings=trainer_settings,\n",
    "        network_settings=network_settings,\n",
    "        tanh_squash=False,\n",
    "        separate_critic=False,\n",
    "        condition_sigma_on_obs=False,\n",
    "        load_critic_only=\"position_only\"\n",
    "    )\n",
    "    modules = policy.get_modules()\n",
    "\n",
    "    # === PRECOMPUTE GRID POSITIONS ===\n",
    "    # Here we build the same 30×30 grid you used interactively\n",
    "    positions = make_grid_positions(-4, 25, -4, 25, step=1)  # gives 30×30 = 900 points\n",
    "\n",
    "    # === FIND & SORT .pt FILES ===\n",
    "    pt_files = glob.glob(os.path.join(seeker_dir, \"*.pt\"))\n",
    "    pt_files.sort(key=natural_sort_key)\n",
    "\n",
    "    print(f\"Found {len(pt_files)} checkpoint files.\")\n",
    "\n",
    "    # If you want to normalize the color scale across all frames,\n",
    "    # you could precompute all values once and track global min/max.\n",
    "    # For simplicity, we do per-frame color scaling here.\n",
    "\n",
    "    frame_paths = []\n",
    "    for idx, ckpt in enumerate(pt_files):\n",
    "        print(f\"[{idx+1}/{len(pt_files)}] Loading {os.path.basename(ckpt)} …\")\n",
    "        sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "        # Strict load of policy weights\n",
    "        modules['Policy'].load_state_dict(sd['Policy'], strict=True)\n",
    "\n",
    "        # Forward pass through critic\n",
    "        vals = policy.actor.critic_pass(positions)[0]['extrinsic']\n",
    "        grid = vals.detach().cpu().numpy().reshape((30, 30))\n",
    "\n",
    "        # Save a PNG frame\n",
    "        frame_path = os.path.join(out_dir, f\"frame_{idx:03d}.png\")\n",
    "        plot_field(grid,\n",
    "                out_path='overlayed.png',\n",
    "                capture_path='map.PNG',\n",
    "                cmap='hot',\n",
    "                alpha=0.5)\n",
    "        frame_paths.append(frame_path)\n",
    "\n",
    "    # === MAKE THE GIF ===\n",
    "    print(f\"Writing GIF to {gif_path}\")\n",
    "    make_gif_from_images(frame_paths, gif_path, fps=2)\n",
    "    print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".visibility-game-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
