{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from trainers.torch.networks import SplitValueSharedActorCritic\n",
    "from mlagents_envs.base_env import ObservationSpec, DimensionProperty, ObservationType\n",
    "from mlagents.trainers.settings import NetworkSettings, TrainerSettings\n",
    "from mlagents_envs.base_env import ActionSpec\n",
    "from trainers.policy.torch_policy import TorchPolicy\n",
    "from mlagents_envs.base_env import BehaviorSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"/home/rmarr/Projects/visibility-game-env/results/dualrun1221/Seeker/checkpoint.pt\"\n",
    "saved_state_dict = torch.load(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5404\n",
    "observation_specs = [ObservationSpec(\n",
    "            name=\"position_observation\",\n",
    "            shape=(3,),  # 3D vector\n",
    "            dimension_property=(DimensionProperty.NONE,),  # Must be a tuple\n",
    "            observation_type=ObservationType.DEFAULT\n",
    "        )]\n",
    "action_spec = ActionSpec(\n",
    "    continuous_size=0,\n",
    "    discrete_branches=(5,)\n",
    ")\n",
    "behavior_spec = BehaviorSpec(\n",
    "    observation_specs=observation_specs,\n",
    "    action_spec=action_spec\n",
    ")\n",
    "trainer_settings = TrainerSettings(\n",
    "    dual_critic=True\n",
    ")\n",
    "# position_obs_spec = [ObservationSpec(\n",
    "#             name=\"position_observation\",\n",
    "#             shape=(3,),  # 3D vector\n",
    "#             dimension_property=(DimensionProperty.NONE,),  # Must be a tuple\n",
    "#             observation_type=ObservationType.DEFAULT\n",
    "#         )]\n",
    "# crumbs_obs_spec = [ObservationSpec(\n",
    "#             name=\"crumbs_observation\",\n",
    "#             shape=(9,),  # 3D vector\n",
    "#             dimension_property=(DimensionProperty.NONE,),  # Must be a tuple\n",
    "#             observation_type=ObservationType.DEFAULT\n",
    "#         )]\n",
    "\n",
    "network_settings = NetworkSettings(\n",
    "    deterministic=False,\n",
    "    memory=None,\n",
    "    hidden_units=128,\n",
    "    num_layers=2,\n",
    ")\n",
    "\n",
    "stream_names = [\"default\"]\n",
    "conditional_sigma = False\n",
    "tanh_squash = False\n",
    "load_critic_only = \"position_only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = TorchPolicy(\n",
    "    seed=0,\n",
    "    behavior_spec=behavior_spec,\n",
    "    trainer_settings=trainer_settings,\n",
    "    tanh_squash=False,\n",
    "    separate_critic=True,\n",
    "    condition_sigma_on_obs=False,\n",
    "    load_critic_only='default'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = policy.get_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, mod in modules.items():\n",
    "    try:\n",
    "        if load_critic_only:\n",
    "\n",
    "            # only use critic network\n",
    "            if \"policy\" in name.lower():\n",
    "                continue\n",
    "            \n",
    "            # only use position_network from critic network\n",
    "            if \"position_only\" in load_critic_only.lower() and \"optimizer:critic\" in name.lower():\n",
    "                position_state_dict = {k: v for k, v in saved_state_dict[name].items() \n",
    "                                    if 'position_network' in k}\n",
    "                mod.load_state_dict(position_state_dict, strict=False)\n",
    "                continue\n",
    "\n",
    "        if isinstance(mod, torch.nn.Module):\n",
    "            missing_keys, unexpected_keys = mod.load_state_dict(\n",
    "                saved_state_dict[name], strict=False\n",
    "            )\n",
    "            if missing_keys:\n",
    "                print(\n",
    "                    f\"Did not find these keys {missing_keys} in checkpoint. Initializing.\"\n",
    "                )\n",
    "            if unexpected_keys:\n",
    "                print.warning(\n",
    "                    f\"Did not expect these keys {unexpected_keys} in checkpoint. Ignoring.\"\n",
    "                )\n",
    "        else:\n",
    "            # If module is not an nn.Module, try to load as one piece\n",
    "            mod.load_state_dict(saved_state_dict[name])\n",
    "\n",
    "    # KeyError is raised if the module was not present in the last run but is being\n",
    "    # accessed in the saved_state_dict.\n",
    "    # ValueError is raised by the optimizer's load_state_dict if the parameters have\n",
    "    # have changed. Note, the optimizer uses a completely different load_state_dict\n",
    "    # function because it is not an nn.Module.\n",
    "    # RuntimeError is raised by PyTorch if there is a size mismatch between modules\n",
    "    # of the same name. This will still partially assign values to those layers that\n",
    "    # have not changed shape.\n",
    "    except (KeyError, ValueError, RuntimeError) as err:\n",
    "        print(f\"Failed to load for module {name}. Initializing\")\n",
    "        print(f\"Module loading error : {err}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.5\n",
      "-8.5\n",
      "-7.5\n",
      "-6.5\n",
      "-5.5\n",
      "-4.5\n",
      "-3.5\n",
      "-2.5\n",
      "-1.5\n",
      "-0.5\n",
      "0.5\n",
      "1.5\n",
      "2.5\n",
      "3.5\n",
      "4.5\n",
      "5.5\n",
      "6.5\n",
      "7.5\n",
      "8.5\n",
      "9.5\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "for x in range(-9, 11, 1):\n",
    "    for y in range(-9, 11, 1):\n",
    "        inputs.append([x-0.5, 0.5, y-0.5])\n",
    "inputs = [torch.tensor(inputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [torch.tensor([[-9.5000,  0.5000, -9.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
    "        [-9.5000,  0.5000, -8.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
    "        [-9.5000,  0.5000, -7.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
    "        ...,\n",
    "        [ 9.5000,  0.5000,  7.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
    "        [ 9.5000,  0.5000,  8.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
    "        [ 9.5000,  0.5000,  9.5000,  ...,  0.0000,  0.0000,  0.0000]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m policy\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mcritic_pass(\u001b[43minputs\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "policy.actor.critic_pass_position(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
